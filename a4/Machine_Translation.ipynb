{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install docopt\n",
        "!pip install docopt sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJKie9sTFANG",
        "outputId": "3ce203af-ec55-46a2-a207-a5795e79b893"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=f4e3233325a510db6f0851bdc9334b1741d9c40c54a7ecf6b4ab076decdc7b96\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: docopt\n",
            "Successfully installed docopt-0.6.2\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.5.15)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.25.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.8.2 sacrebleu-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlrYIOa0AYUI",
        "outputId": "b3157f82-4ee9-4fe0-943d-6ecd0e16e6ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/a4')"
      ],
      "metadata": {
        "id": "_f81vbeYAiu3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRElUMAkC-UP",
        "outputId": "a3b7e141-9e19-4f4b-c37f-6fc23d903288"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chr_en_data\t\tlocal_env.yml\t     README.md\t\t      sanity_check.py  utils.py\n",
            "collect_submission.bat\tmodel_embeddings.py  run.bat\t\t      src.model        vocab.json\n",
            "collect_submission.sh\tnmt_model.py\t     run.py\t\t      src.vocab        vocab.py\n",
            "gpu_requirements.txt\toutputs\t\t     run.sh\t\t      tgt.model\n",
            "__init__.py\t\t__pycache__\t     sanity_check_en_es_data  tgt.vocab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x run.sh"
      ],
      "metadata": {
        "id": "e6A-9x5uDPky"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 vocab.py --train-src=./chr_en_data/train.chr --train-tgt=./chr_en_data/train.en vocab.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qhvioasDUp-",
        "outputId": "172170d7-fbbf-462b-fabf-e998323bf33b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "read in source sentences: ./chr_en_data/train.chr\n",
            "read in target sentences: ./chr_en_data/train.en\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: ./chr_en_data/train.chr\n",
            "  input_format: \n",
            "  model_prefix: src\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 21000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  pretokenization_delimiter: \n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(183) LOG(INFO) Loading corpus: ./chr_en_data/train.chr\n",
            "trainer_interface.cc(407) LOG(INFO) Loaded all 16696 sentences\n",
            "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(537) LOG(INFO) all chars count=1024249\n",
            "trainer_interface.cc(548) LOG(INFO) Done: 99.95% characters are covered.\n",
            "trainer_interface.cc(558) LOG(INFO) Alphabet size=115\n",
            "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.9995\n",
            "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 16696 sentences.\n",
            "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=471384\n",
            "unigram_model_trainer.cc(274) LOG(INFO) Initialized 71584 seed sentencepieces\n",
            "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 16696\n",
            "trainer_interface.cc(608) LOG(INFO) Done! 54339\n",
            "unigram_model_trainer.cc(564) LOG(INFO) Using 54339 sentences for EM training\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=31853 obj=13.2384 num_tokens=118297 num_tokens/piece=3.71384\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=28580 obj=11.3757 num_tokens=118524 num_tokens/piece=4.1471\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=23085 obj=11.397 num_tokens=122902 num_tokens/piece=5.32389\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=22989 obj=11.3479 num_tokens=122932 num_tokens/piece=5.34743\n",
            "trainer_interface.cc(686) LOG(INFO) Saving model: src.model\n",
            "trainer_interface.cc(698) LOG(INFO) Saving vocabs: src.vocab\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: ./chr_en_data/train.en\n",
            "  input_format: \n",
            "  model_prefix: tgt\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 8000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  pretokenization_delimiter: \n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(183) LOG(INFO) Loading corpus: ./chr_en_data/train.en\n",
            "trainer_interface.cc(407) LOG(INFO) Loaded all 16696 sentences\n",
            "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(537) LOG(INFO) all chars count=1642445\n",
            "trainer_interface.cc(548) LOG(INFO) Done: 99.9521% characters are covered.\n",
            "trainer_interface.cc(558) LOG(INFO) Alphabet size=61\n",
            "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999521\n",
            "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 16696 sentences.\n",
            "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=888407\n",
            "unigram_model_trainer.cc(274) LOG(INFO) Initialized 35820 seed sentencepieces\n",
            "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 16696\n",
            "trainer_interface.cc(608) LOG(INFO) Done! 24681\n",
            "unigram_model_trainer.cc(564) LOG(INFO) Using 24681 sentences for EM training\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=12950 obj=9.92202 num_tokens=48774 num_tokens/piece=3.76633\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=10769 obj=7.89767 num_tokens=48939 num_tokens/piece=4.54443\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=8796 obj=7.84668 num_tokens=50676 num_tokens/piece=5.76126\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=8788 obj=7.82746 num_tokens=50686 num_tokens/piece=5.76764\n",
            "trainer_interface.cc(686) LOG(INFO) Saving model: tgt.model\n",
            "trainer_interface.cc(698) LOG(INFO) Saving vocabs: tgt.vocab\n",
            "initialize source vocabulary ..\n",
            "initialize target vocabulary ..\n",
            "generated vocabulary, source 21000 words, target 8000 words\n",
            "vocabulary saved to vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 run.py train --train-src=./chr_en_data/train.chr --train-tgt=./chr_en_data/train.en --dev-src=./chr_en_data/dev.chr --dev-tgt=./chr_en_data/dev.en --vocab=vocab.json --lr=5e-4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfCTS_7oDZ8i",
        "outputId": "b0f579bb-6923-4974-93d4-0da9354f5521"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "2024-06-19 06:05:01.213662: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-19 06:05:01.213714: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-19 06:05:01.215073: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-19 06:05:01.222030: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-19 06:05:02.258038: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "uniformly initialize parameters [-0.100000, +0.100000]\n",
            "use device: cpu\n",
            "begin Maximum Likelihood training\n",
            "epoch 1, iter 10, avg. loss 197.96, avg. ppl 3053.00 cum. examples 320, speed 70.10 words/sec, time elapsed 112.63 sec\n",
            "epoch 1, iter 20, avg. loss 166.03, avg. ppl 808.27 cum. examples 640, speed 80.19 words/sec, time elapsed 211.59 sec\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r gpu_requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G7KbrDMFmAU",
        "outputId": "5dca81aa-88e4-4bab-8302-fc2a77854d54"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from -r gpu_requirements.txt (line 1)) (3.8.1)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from -r gpu_requirements.txt (line 2)) (0.6.2)\n",
            "Collecting tqdm==4.29.1 (from -r gpu_requirements.txt (line 3))\n",
            "  Downloading tqdm-4.29.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r gpu_requirements.txt (line 4)) (0.1.99)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (from -r gpu_requirements.txt (line 5)) (2.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r gpu_requirements.txt (line 6)) (2.3.0+cu121)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->-r gpu_requirements.txt (line 1)) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->-r gpu_requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->-r gpu_requirements.txt (line 1)) (2024.5.15)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu->-r gpu_requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->-r gpu_requirements.txt (line 5)) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->-r gpu_requirements.txt (line 5)) (1.25.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu->-r gpu_requirements.txt (line 5)) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->-r gpu_requirements.txt (line 5)) (4.9.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r gpu_requirements.txt (line 6)) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r gpu_requirements.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r gpu_requirements.txt (line 6)) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r gpu_requirements.txt (line 6)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r gpu_requirements.txt (line 6)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r gpu_requirements.txt (line 6)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->-r gpu_requirements.txt (line 6))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->-r gpu_requirements.txt (line 6))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->-r gpu_requirements.txt (line 6))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->-r gpu_requirements.txt (line 6))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->-r gpu_requirements.txt (line 6))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->-r gpu_requirements.txt (line 6))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->-r gpu_requirements.txt (line 6))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->-r gpu_requirements.txt (line 6))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->-r gpu_requirements.txt (line 6))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->-r gpu_requirements.txt (line 6))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->-r gpu_requirements.txt (line 6))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r gpu_requirements.txt (line 6)) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->-r gpu_requirements.txt (line 6))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r gpu_requirements.txt (line 6)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r gpu_requirements.txt (line 6)) (1.3.0)\n",
            "Installing collected packages: tqdm, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.4\n",
            "    Uninstalling tqdm-4.66.4:\n",
            "      Successfully uninstalled tqdm-4.66.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.0.9 requires tqdm>=4.64.1, but you have tqdm 4.29.1 which is incompatible.\n",
            "huggingface-hub 0.23.3 requires tqdm>=4.42.1, but you have tqdm 4.29.1 which is incompatible.\n",
            "panel 1.3.8 requires tqdm>=4.48.0, but you have tqdm 4.29.1 which is incompatible.\n",
            "prophet 1.1.5 requires tqdm>=4.36.1, but you have tqdm 4.29.1 which is incompatible.\n",
            "spacy 3.7.5 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 tqdm-4.29.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python3 run.py train --train-src=./chr_en_data/train.chr --train-tgt=./chr_en_data/train.en --dev-src=./chr_en_data/dev.chr --dev-tgt=./chr_en_data/dev.en --vocab=vocab.json --cuda --lr=5e-4 --patience=1 --valid-niter=200 --batch-size=32 --dropout=.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNOrfF6SHPfz",
        "outputId": "af34b17b-49c9-456e-e598-1a4fff04e0d3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "2024-06-19 06:10:33.074801: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-19 06:10:33.074855: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-19 06:10:33.076156: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-19 06:10:33.083676: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-19 06:10:34.147955: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "uniformly initialize parameters [-0.100000, +0.100000]\n",
            "use device: cuda:0\n",
            "begin Maximum Likelihood training\n",
            "epoch 1, iter 10, avg. loss 198.82, avg. ppl 3160.92 cum. examples 320, speed 1820.52 words/sec, time elapsed 4.34 sec\n",
            "epoch 1, iter 20, avg. loss 165.36, avg. ppl 786.75 cum. examples 640, speed 3483.50 words/sec, time elapsed 6.62 sec\n",
            "epoch 1, iter 30, avg. loss 147.15, avg. ppl 537.94 cum. examples 960, speed 3308.42 words/sec, time elapsed 8.88 sec\n",
            "epoch 1, iter 40, avg. loss 146.72, avg. ppl 433.33 cum. examples 1280, speed 3491.35 words/sec, time elapsed 11.09 sec\n",
            "epoch 1, iter 50, avg. loss 148.21, avg. ppl 396.67 cum. examples 1600, speed 3687.44 words/sec, time elapsed 13.24 sec\n",
            "epoch 1, iter 60, avg. loss 154.28, avg. ppl 374.95 cum. examples 1920, speed 3471.01 words/sec, time elapsed 15.64 sec\n",
            "epoch 1, iter 70, avg. loss 147.01, avg. ppl 326.09 cum. examples 2240, speed 3621.19 words/sec, time elapsed 17.89 sec\n",
            "epoch 1, iter 80, avg. loss 139.17, avg. ppl 285.99 cum. examples 2560, speed 3524.43 words/sec, time elapsed 20.12 sec\n",
            "epoch 1, iter 90, avg. loss 129.19, avg. ppl 289.45 cum. examples 2880, speed 3659.68 words/sec, time elapsed 22.12 sec\n",
            "epoch 1, iter 100, avg. loss 139.38, avg. ppl 280.23 cum. examples 3200, speed 3230.07 words/sec, time elapsed 24.57 sec\n",
            "epoch 1, iter 110, avg. loss 129.88, avg. ppl 222.92 cum. examples 3520, speed 3811.42 words/sec, time elapsed 26.58 sec\n",
            "epoch 1, iter 120, avg. loss 124.64, avg. ppl 211.53 cum. examples 3840, speed 3518.57 words/sec, time elapsed 28.70 sec\n",
            "epoch 1, iter 130, avg. loss 133.70, avg. ppl 214.00 cum. examples 4160, speed 3294.23 words/sec, time elapsed 31.12 sec\n",
            "epoch 1, iter 140, avg. loss 125.26, avg. ppl 179.86 cum. examples 4480, speed 3205.61 words/sec, time elapsed 33.53 sec\n",
            "epoch 1, iter 150, avg. loss 130.57, avg. ppl 185.56 cum. examples 4800, speed 3228.68 words/sec, time elapsed 36.01 sec\n",
            "epoch 1, iter 160, avg. loss 134.03, avg. ppl 187.94 cum. examples 5120, speed 3607.32 words/sec, time elapsed 38.28 sec\n",
            "epoch 1, iter 170, avg. loss 121.82, avg. ppl 170.01 cum. examples 5440, speed 3285.09 words/sec, time elapsed 40.59 sec\n",
            "epoch 1, iter 180, avg. loss 129.52, avg. ppl 152.17 cum. examples 5760, speed 3660.99 words/sec, time elapsed 42.84 sec\n",
            "epoch 1, iter 190, avg. loss 117.37, avg. ppl 137.77 cum. examples 6080, speed 3340.46 words/sec, time elapsed 45.12 sec\n",
            "epoch 1, iter 200, avg. loss 117.97, avg. ppl 143.97 cum. examples 6400, speed 3233.75 words/sec, time elapsed 47.47 sec\n",
            "epoch 1, iter 200, cum. loss 139.00, cum. ppl 293.20 cum. examples 6400\n",
            "begin validation ...\n",
            "validation: iter 200, dev. ppl 156.283682\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 1, iter 210, avg. loss 121.22, avg. ppl 134.93 cum. examples 320, speed 1029.87 words/sec, time elapsed 55.15 sec\n",
            "epoch 1, iter 220, avg. loss 112.91, avg. ppl 131.37 cum. examples 640, speed 3283.09 words/sec, time elapsed 57.41 sec\n",
            "epoch 1, iter 230, avg. loss 114.43, avg. ppl 118.83 cum. examples 960, speed 3417.10 words/sec, time elapsed 59.65 sec\n",
            "epoch 1, iter 240, avg. loss 121.61, avg. ppl 133.28 cum. examples 1280, speed 2954.82 words/sec, time elapsed 62.35 sec\n",
            "epoch 1, iter 250, avg. loss 120.22, avg. ppl 132.06 cum. examples 1600, speed 3252.78 words/sec, time elapsed 64.77 sec\n",
            "epoch 1, iter 260, avg. loss 117.51, avg. ppl 124.83 cum. examples 1920, speed 3253.34 words/sec, time elapsed 67.16 sec\n",
            "epoch 1, iter 270, avg. loss 114.90, avg. ppl 120.32 cum. examples 2240, speed 3220.45 words/sec, time elapsed 69.55 sec\n",
            "epoch 1, iter 280, avg. loss 117.31, avg. ppl 114.96 cum. examples 2560, speed 3234.44 words/sec, time elapsed 71.99 sec\n",
            "epoch 1, iter 290, avg. loss 115.35, avg. ppl 121.05 cum. examples 2880, speed 3155.00 words/sec, time elapsed 74.43 sec\n",
            "epoch 1, iter 300, avg. loss 115.00, avg. ppl 104.62 cum. examples 3200, speed 3372.21 words/sec, time elapsed 76.78 sec\n",
            "epoch 1, iter 310, avg. loss 111.62, avg. ppl 104.43 cum. examples 3520, speed 3415.46 words/sec, time elapsed 79.03 sec\n",
            "epoch 1, iter 320, avg. loss 112.69, avg. ppl 106.09 cum. examples 3840, speed 3511.40 words/sec, time elapsed 81.23 sec\n",
            "epoch 1, iter 330, avg. loss 117.66, avg. ppl 105.30 cum. examples 4160, speed 3573.41 words/sec, time elapsed 83.49 sec\n",
            "epoch 1, iter 340, avg. loss 113.18, avg. ppl 104.27 cum. examples 4480, speed 2967.20 words/sec, time elapsed 86.12 sec\n",
            "epoch 1, iter 350, avg. loss 115.85, avg. ppl 111.19 cum. examples 4800, speed 3592.77 words/sec, time elapsed 88.31 sec\n",
            "epoch 1, iter 360, avg. loss 112.64, avg. ppl 92.42 cum. examples 5120, speed 3299.24 words/sec, time elapsed 90.72 sec\n",
            "epoch 1, iter 370, avg. loss 112.06, avg. ppl 89.54 cum. examples 5440, speed 3411.33 words/sec, time elapsed 93.06 sec\n",
            "epoch 1, iter 380, avg. loss 109.92, avg. ppl 94.44 cum. examples 5760, speed 3500.57 words/sec, time elapsed 95.27 sec\n",
            "epoch 1, iter 390, avg. loss 102.59, avg. ppl 77.24 cum. examples 6080, speed 3500.12 words/sec, time elapsed 97.43 sec\n",
            "epoch 1, iter 400, avg. loss 106.27, avg. ppl 90.98 cum. examples 6400, speed 3692.92 words/sec, time elapsed 99.47 sec\n",
            "epoch 1, iter 400, cum. loss 114.25, cum. ppl 109.42 cum. examples 6400\n",
            "begin validation ...\n",
            "validation: iter 400, dev. ppl 95.607099\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 1, iter 410, avg. loss 103.23, avg. ppl 84.63 cum. examples 320, speed 662.74 words/sec, time elapsed 110.70 sec\n",
            "epoch 1, iter 420, avg. loss 108.96, avg. ppl 89.62 cum. examples 640, speed 3627.87 words/sec, time elapsed 112.84 sec\n",
            "epoch 1, iter 430, avg. loss 112.30, avg. ppl 87.62 cum. examples 960, speed 3359.73 words/sec, time elapsed 115.23 sec\n",
            "epoch 1, iter 440, avg. loss 110.73, avg. ppl 79.48 cum. examples 1280, speed 3494.71 words/sec, time elapsed 117.55 sec\n",
            "epoch 1, iter 450, avg. loss 109.00, avg. ppl 86.76 cum. examples 1600, speed 3212.13 words/sec, time elapsed 119.98 sec\n",
            "epoch 1, iter 460, avg. loss 105.78, avg. ppl 82.10 cum. examples 1920, speed 3192.17 words/sec, time elapsed 122.39 sec\n",
            "epoch 1, iter 470, avg. loss 103.11, avg. ppl 64.15 cum. examples 2240, speed 3817.79 words/sec, time elapsed 124.46 sec\n",
            "epoch 1, iter 480, avg. loss 104.57, avg. ppl 65.26 cum. examples 2560, speed 3529.04 words/sec, time elapsed 126.73 sec\n",
            "epoch 1, iter 490, avg. loss 106.33, avg. ppl 76.10 cum. examples 2880, speed 3332.03 words/sec, time elapsed 129.09 sec\n",
            "epoch 1, iter 500, avg. loss 103.58, avg. ppl 71.37 cum. examples 3200, speed 3127.96 words/sec, time elapsed 131.57 sec\n",
            "epoch 1, iter 510, avg. loss 102.07, avg. ppl 75.96 cum. examples 3520, speed 2796.40 words/sec, time elapsed 134.27 sec\n",
            "epoch 1, iter 520, avg. loss 108.62, avg. ppl 77.37 cum. examples 3840, speed 3529.63 words/sec, time elapsed 136.54 sec\n",
            "epoch 2, iter 530, avg. loss 95.88, avg. ppl 53.13 cum. examples 4152, speed 3449.14 words/sec, time elapsed 138.72 sec\n",
            "epoch 2, iter 540, avg. loss 98.51, avg. ppl 54.29 cum. examples 4472, speed 3489.87 words/sec, time elapsed 140.98 sec\n",
            "epoch 2, iter 550, avg. loss 96.12, avg. ppl 50.54 cum. examples 4792, speed 3554.02 words/sec, time elapsed 143.19 sec\n",
            "epoch 2, iter 560, avg. loss 96.47, avg. ppl 52.09 cum. examples 5112, speed 3142.50 words/sec, time elapsed 145.67 sec\n",
            "epoch 2, iter 570, avg. loss 100.40, avg. ppl 47.89 cum. examples 5432, speed 3379.38 words/sec, time elapsed 148.13 sec\n",
            "epoch 2, iter 580, avg. loss 93.09, avg. ppl 48.03 cum. examples 5752, speed 3485.19 words/sec, time elapsed 150.34 sec\n",
            "epoch 2, iter 590, avg. loss 90.93, avg. ppl 47.73 cum. examples 6072, speed 3454.91 words/sec, time elapsed 152.52 sec\n",
            "epoch 2, iter 600, avg. loss 95.05, avg. ppl 50.14 cum. examples 6392, speed 3563.49 words/sec, time elapsed 154.70 sec\n",
            "epoch 2, iter 600, cum. loss 102.24, cum. ppl 65.48 cum. examples 6392\n",
            "begin validation ...\n",
            "validation: iter 600, dev. ppl 70.409527\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 2, iter 610, avg. loss 95.86, avg. ppl 52.31 cum. examples 320, speed 936.75 words/sec, time elapsed 162.97 sec\n",
            "epoch 2, iter 620, avg. loss 95.17, avg. ppl 51.93 cum. examples 640, speed 3491.45 words/sec, time elapsed 165.18 sec\n",
            "epoch 2, iter 630, avg. loss 91.57, avg. ppl 42.11 cum. examples 960, speed 3586.02 words/sec, time elapsed 167.37 sec\n",
            "epoch 2, iter 640, avg. loss 97.10, avg. ppl 48.67 cum. examples 1280, speed 3154.12 words/sec, time elapsed 169.90 sec\n",
            "epoch 2, iter 650, avg. loss 97.77, avg. ppl 48.41 cum. examples 1600, speed 3333.76 words/sec, time elapsed 172.32 sec\n",
            "epoch 2, iter 660, avg. loss 96.05, avg. ppl 47.20 cum. examples 1920, speed 3139.58 words/sec, time elapsed 174.86 sec\n",
            "epoch 2, iter 670, avg. loss 89.67, avg. ppl 43.37 cum. examples 2240, speed 3119.93 words/sec, time elapsed 177.30 sec\n",
            "epoch 2, iter 680, avg. loss 92.86, avg. ppl 47.57 cum. examples 2560, speed 2814.62 words/sec, time elapsed 180.03 sec\n",
            "epoch 2, iter 690, avg. loss 93.72, avg. ppl 45.32 cum. examples 2880, speed 3492.61 words/sec, time elapsed 182.29 sec\n",
            "epoch 2, iter 700, avg. loss 87.68, avg. ppl 42.09 cum. examples 3200, speed 3101.68 words/sec, time elapsed 184.70 sec\n",
            "epoch 2, iter 710, avg. loss 95.23, avg. ppl 41.09 cum. examples 3520, speed 3164.86 words/sec, time elapsed 187.30 sec\n",
            "epoch 2, iter 720, avg. loss 92.58, avg. ppl 45.20 cum. examples 3840, speed 3141.65 words/sec, time elapsed 189.77 sec\n",
            "epoch 2, iter 730, avg. loss 93.53, avg. ppl 46.69 cum. examples 4160, speed 3470.43 words/sec, time elapsed 192.01 sec\n",
            "epoch 2, iter 740, avg. loss 100.08, avg. ppl 44.55 cum. examples 4480, speed 3309.22 words/sec, time elapsed 194.56 sec\n",
            "epoch 2, iter 750, avg. loss 95.06, avg. ppl 42.75 cum. examples 4800, speed 3640.92 words/sec, time elapsed 196.79 sec\n",
            "epoch 2, iter 760, avg. loss 96.46, avg. ppl 49.89 cum. examples 5120, speed 3239.23 words/sec, time elapsed 199.23 sec\n",
            "epoch 2, iter 770, avg. loss 86.11, avg. ppl 44.28 cum. examples 5440, speed 2885.55 words/sec, time elapsed 201.75 sec\n",
            "epoch 2, iter 780, avg. loss 92.34, avg. ppl 41.19 cum. examples 5760, speed 3441.33 words/sec, time elapsed 204.06 sec\n",
            "epoch 2, iter 790, avg. loss 92.34, avg. ppl 43.18 cum. examples 6080, speed 3134.62 words/sec, time elapsed 206.56 sec\n",
            "epoch 2, iter 800, avg. loss 90.07, avg. ppl 44.76 cum. examples 6400, speed 3112.40 words/sec, time elapsed 209.00 sec\n",
            "epoch 2, iter 800, cum. loss 93.56, cum. ppl 45.51 cum. examples 6400\n",
            "begin validation ...\n",
            "validation: iter 800, dev. ppl 56.956990\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 2, iter 810, avg. loss 94.90, avg. ppl 45.65 cum. examples 320, speed 1000.91 words/sec, time elapsed 216.94 sec\n",
            "epoch 2, iter 820, avg. loss 86.55, avg. ppl 43.12 cum. examples 640, speed 3111.12 words/sec, time elapsed 219.30 sec\n",
            "epoch 2, iter 830, avg. loss 95.16, avg. ppl 44.53 cum. examples 960, speed 3580.71 words/sec, time elapsed 221.54 sec\n",
            "epoch 2, iter 840, avg. loss 87.48, avg. ppl 42.95 cum. examples 1280, speed 3210.40 words/sec, time elapsed 223.86 sec\n",
            "epoch 2, iter 850, avg. loss 92.09, avg. ppl 37.01 cum. examples 1600, speed 3398.49 words/sec, time elapsed 226.26 sec\n",
            "epoch 2, iter 860, avg. loss 93.47, avg. ppl 44.92 cum. examples 1920, speed 3333.31 words/sec, time elapsed 228.62 sec\n",
            "epoch 2, iter 870, avg. loss 92.96, avg. ppl 42.60 cum. examples 2240, speed 3238.48 words/sec, time elapsed 231.07 sec\n",
            "epoch 2, iter 880, avg. loss 89.66, avg. ppl 41.46 cum. examples 2560, speed 3098.44 words/sec, time elapsed 233.56 sec\n",
            "epoch 2, iter 890, avg. loss 86.91, avg. ppl 42.01 cum. examples 2880, speed 3168.38 words/sec, time elapsed 235.90 sec\n",
            "epoch 2, iter 900, avg. loss 89.66, avg. ppl 39.58 cum. examples 3200, speed 3496.21 words/sec, time elapsed 238.14 sec\n",
            "epoch 2, iter 910, avg. loss 90.39, avg. ppl 41.63 cum. examples 3520, speed 3192.95 words/sec, time elapsed 240.57 sec\n",
            "epoch 2, iter 920, avg. loss 88.98, avg. ppl 37.45 cum. examples 3840, speed 3412.59 words/sec, time elapsed 242.87 sec\n",
            "epoch 2, iter 930, avg. loss 91.87, avg. ppl 37.11 cum. examples 4160, speed 3417.60 words/sec, time elapsed 245.25 sec\n",
            "epoch 2, iter 940, avg. loss 85.94, avg. ppl 38.14 cum. examples 4480, speed 3127.36 words/sec, time elapsed 247.67 sec\n",
            "epoch 2, iter 950, avg. loss 89.92, avg. ppl 42.18 cum. examples 4800, speed 3160.73 words/sec, time elapsed 250.10 sec\n",
            "epoch 2, iter 960, avg. loss 85.55, avg. ppl 38.91 cum. examples 5120, speed 2991.50 words/sec, time elapsed 252.60 sec\n",
            "epoch 2, iter 970, avg. loss 83.57, avg. ppl 34.89 cum. examples 5440, speed 3617.31 words/sec, time elapsed 254.68 sec\n",
            "epoch 2, iter 980, avg. loss 96.67, avg. ppl 44.18 cum. examples 5760, speed 3289.91 words/sec, time elapsed 257.16 sec\n",
            "epoch 2, iter 990, avg. loss 89.90, avg. ppl 35.63 cum. examples 6080, speed 3475.84 words/sec, time elapsed 259.48 sec\n",
            "epoch 2, iter 1000, avg. loss 89.72, avg. ppl 39.29 cum. examples 6400, speed 3366.91 words/sec, time elapsed 261.80 sec\n",
            "epoch 2, iter 1000, cum. loss 90.07, cum. ppl 40.53 cum. examples 6400\n",
            "begin validation ...\n",
            "validation: iter 1000, dev. ppl 49.437865\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 2, iter 1010, avg. loss 89.49, avg. ppl 36.93 cum. examples 320, speed 629.22 words/sec, time elapsed 274.41 sec\n",
            "epoch 2, iter 1020, avg. loss 85.04, avg. ppl 33.86 cum. examples 640, speed 3450.37 words/sec, time elapsed 276.65 sec\n",
            "epoch 2, iter 1030, avg. loss 86.16, avg. ppl 33.42 cum. examples 960, speed 3035.35 words/sec, time elapsed 279.24 sec\n",
            "epoch 2, iter 1040, avg. loss 86.98, avg. ppl 34.35 cum. examples 1280, speed 3153.31 words/sec, time elapsed 281.74 sec\n",
            "epoch 3, iter 1050, avg. loss 81.84, avg. ppl 30.34 cum. examples 1592, speed 2953.50 words/sec, time elapsed 284.27 sec\n",
            "epoch 3, iter 1060, avg. loss 74.27, avg. ppl 22.35 cum. examples 1912, speed 3351.68 words/sec, time elapsed 286.56 sec\n",
            "epoch 3, iter 1070, avg. loss 73.93, avg. ppl 23.81 cum. examples 2232, speed 3089.26 words/sec, time elapsed 288.97 sec\n",
            "epoch 3, iter 1080, avg. loss 74.82, avg. ppl 22.00 cum. examples 2552, speed 3521.63 words/sec, time elapsed 291.17 sec\n",
            "epoch 3, iter 1090, avg. loss 78.10, avg. ppl 22.80 cum. examples 2872, speed 3188.19 words/sec, time elapsed 293.68 sec\n",
            "epoch 3, iter 1100, avg. loss 76.67, avg. ppl 23.04 cum. examples 3192, speed 3136.74 words/sec, time elapsed 296.17 sec\n",
            "epoch 3, iter 1110, avg. loss 75.23, avg. ppl 22.36 cum. examples 3512, speed 3185.00 words/sec, time elapsed 298.60 sec\n",
            "epoch 3, iter 1120, avg. loss 75.27, avg. ppl 21.55 cum. examples 3832, speed 3303.75 words/sec, time elapsed 300.98 sec\n",
            "epoch 3, iter 1130, avg. loss 79.43, avg. ppl 23.87 cum. examples 4152, speed 3005.68 words/sec, time elapsed 303.65 sec\n",
            "epoch 3, iter 1140, avg. loss 79.41, avg. ppl 23.22 cum. examples 4472, speed 3266.30 words/sec, time elapsed 306.12 sec\n",
            "epoch 3, iter 1150, avg. loss 67.84, avg. ppl 19.42 cum. examples 4792, speed 3318.09 words/sec, time elapsed 308.32 sec\n",
            "epoch 3, iter 1160, avg. loss 79.15, avg. ppl 22.74 cum. examples 5112, speed 3342.30 words/sec, time elapsed 310.75 sec\n",
            "epoch 3, iter 1170, avg. loss 75.70, avg. ppl 22.19 cum. examples 5432, speed 3436.61 words/sec, time elapsed 313.02 sec\n",
            "epoch 3, iter 1180, avg. loss 75.54, avg. ppl 21.77 cum. examples 5752, speed 3520.84 words/sec, time elapsed 315.25 sec\n",
            "epoch 3, iter 1190, avg. loss 75.46, avg. ppl 22.93 cum. examples 6072, speed 3483.80 words/sec, time elapsed 317.47 sec\n",
            "epoch 3, iter 1200, avg. loss 75.79, avg. ppl 21.59 cum. examples 6392, speed 3378.91 words/sec, time elapsed 319.80 sec\n",
            "epoch 3, iter 1200, cum. loss 78.30, cum. ppl 24.78 cum. examples 6392\n",
            "begin validation ...\n",
            "validation: iter 1200, dev. ppl 45.681163\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 3, iter 1210, avg. loss 71.32, avg. ppl 20.75 cum. examples 320, speed 909.51 words/sec, time elapsed 328.08 sec\n",
            "epoch 3, iter 1220, avg. loss 75.66, avg. ppl 22.05 cum. examples 640, speed 3301.85 words/sec, time elapsed 330.45 sec\n",
            "epoch 3, iter 1230, avg. loss 70.25, avg. ppl 19.42 cum. examples 960, speed 3317.96 words/sec, time elapsed 332.73 sec\n",
            "epoch 3, iter 1240, avg. loss 74.13, avg. ppl 20.85 cum. examples 1280, speed 3216.80 words/sec, time elapsed 335.16 sec\n",
            "epoch 3, iter 1250, avg. loss 76.18, avg. ppl 20.92 cum. examples 1600, speed 3382.89 words/sec, time elapsed 337.53 sec\n",
            "epoch 3, iter 1260, avg. loss 72.94, avg. ppl 20.42 cum. examples 1920, speed 3567.09 words/sec, time elapsed 339.70 sec\n",
            "epoch 3, iter 1270, avg. loss 75.64, avg. ppl 23.22 cum. examples 2240, speed 3259.31 words/sec, time elapsed 342.06 sec\n",
            "epoch 3, iter 1280, avg. loss 77.50, avg. ppl 21.73 cum. examples 2560, speed 3540.22 words/sec, time elapsed 344.34 sec\n",
            "epoch 3, iter 1290, avg. loss 76.74, avg. ppl 21.83 cum. examples 2880, speed 3410.95 words/sec, time elapsed 346.67 sec\n",
            "epoch 3, iter 1300, avg. loss 74.82, avg. ppl 19.96 cum. examples 3200, speed 3130.21 words/sec, time elapsed 349.23 sec\n",
            "epoch 3, iter 1310, avg. loss 74.63, avg. ppl 19.54 cum. examples 3520, speed 3274.91 words/sec, time elapsed 351.68 sec\n",
            "epoch 3, iter 1320, avg. loss 74.89, avg. ppl 19.94 cum. examples 3840, speed 3395.66 words/sec, time elapsed 354.04 sec\n",
            "epoch 3, iter 1330, avg. loss 73.38, avg. ppl 21.44 cum. examples 4160, speed 2972.17 words/sec, time elapsed 356.62 sec\n",
            "epoch 3, iter 1340, avg. loss 76.09, avg. ppl 20.73 cum. examples 4480, speed 3417.02 words/sec, time elapsed 358.97 sec\n",
            "epoch 3, iter 1350, avg. loss 76.06, avg. ppl 21.51 cum. examples 4800, speed 3694.82 words/sec, time elapsed 361.11 sec\n",
            "epoch 3, iter 1360, avg. loss 71.23, avg. ppl 20.10 cum. examples 5120, speed 3534.85 words/sec, time elapsed 363.26 sec\n",
            "epoch 3, iter 1370, avg. loss 80.17, avg. ppl 25.22 cum. examples 5440, speed 3131.22 words/sec, time elapsed 365.80 sec\n",
            "epoch 3, iter 1380, avg. loss 72.30, avg. ppl 20.68 cum. examples 5760, speed 3278.63 words/sec, time elapsed 368.13 sec\n",
            "epoch 3, iter 1390, avg. loss 73.43, avg. ppl 21.93 cum. examples 6080, speed 3444.89 words/sec, time elapsed 370.34 sec\n",
            "epoch 3, iter 1400, avg. loss 77.77, avg. ppl 22.65 cum. examples 6400, speed 3219.50 words/sec, time elapsed 372.82 sec\n",
            "epoch 3, iter 1400, cum. loss 74.76, cum. ppl 21.21 cum. examples 6400\n",
            "begin validation ...\n",
            "validation: iter 1400, dev. ppl 41.293613\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 3, iter 1410, avg. loss 72.16, avg. ppl 19.13 cum. examples 320, speed 934.04 words/sec, time elapsed 381.19 sec\n",
            "epoch 3, iter 1420, avg. loss 72.92, avg. ppl 19.69 cum. examples 640, speed 3454.08 words/sec, time elapsed 383.46 sec\n",
            "epoch 3, iter 1430, avg. loss 71.22, avg. ppl 19.39 cum. examples 960, speed 3120.68 words/sec, time elapsed 385.92 sec\n",
            "epoch 3, iter 1440, avg. loss 69.80, avg. ppl 19.45 cum. examples 1280, speed 3479.39 words/sec, time elapsed 388.09 sec\n",
            "epoch 3, iter 1450, avg. loss 73.83, avg. ppl 21.32 cum. examples 1600, speed 3332.40 words/sec, time elapsed 390.41 sec\n",
            "epoch 3, iter 1460, avg. loss 71.91, avg. ppl 19.42 cum. examples 1920, speed 3045.17 words/sec, time elapsed 392.95 sec\n",
            "epoch 3, iter 1470, avg. loss 72.98, avg. ppl 22.59 cum. examples 2240, speed 3320.68 words/sec, time elapsed 395.21 sec\n",
            "epoch 3, iter 1480, avg. loss 77.21, avg. ppl 21.65 cum. examples 2560, speed 3015.38 words/sec, time elapsed 397.87 sec\n",
            "epoch 3, iter 1490, avg. loss 70.27, avg. ppl 17.81 cum. examples 2880, speed 3426.30 words/sec, time elapsed 400.15 sec\n",
            "epoch 3, iter 1500, avg. loss 74.69, avg. ppl 19.90 cum. examples 3200, speed 3296.52 words/sec, time elapsed 402.58 sec\n",
            "epoch 3, iter 1510, avg. loss 75.53, avg. ppl 21.47 cum. examples 3520, speed 3334.04 words/sec, time elapsed 404.94 sec\n",
            "epoch 3, iter 1520, avg. loss 71.11, avg. ppl 18.73 cum. examples 3840, speed 3253.14 words/sec, time elapsed 407.33 sec\n",
            "epoch 3, iter 1530, avg. loss 72.36, avg. ppl 20.42 cum. examples 4160, speed 2914.80 words/sec, time elapsed 409.96 sec\n",
            "epoch 3, iter 1540, avg. loss 80.72, avg. ppl 21.65 cum. examples 4480, speed 3192.36 words/sec, time elapsed 412.59 sec\n",
            "epoch 3, iter 1550, avg. loss 76.86, avg. ppl 21.72 cum. examples 4800, speed 2899.48 words/sec, time elapsed 415.35 sec\n",
            "epoch 3, iter 1560, avg. loss 71.37, avg. ppl 19.48 cum. examples 5120, speed 3342.97 words/sec, time elapsed 417.65 sec\n",
            "epoch 4, iter 1570, avg. loss 64.64, avg. ppl 16.51 cum. examples 5432, speed 3382.12 words/sec, time elapsed 419.78 sec\n",
            "epoch 4, iter 1580, avg. loss 63.46, avg. ppl 11.61 cum. examples 5752, speed 3598.98 words/sec, time elapsed 422.08 sec\n",
            "epoch 4, iter 1590, avg. loss 62.72, avg. ppl 12.25 cum. examples 6072, speed 3051.50 words/sec, time elapsed 424.71 sec\n",
            "epoch 4, iter 1600, avg. loss 63.07, avg. ppl 12.66 cum. examples 6392, speed 3379.53 words/sec, time elapsed 427.06 sec\n",
            "epoch 4, iter 1600, cum. loss 71.45, cum. ppl 18.50 cum. examples 6392\n",
            "begin validation ...\n",
            "validation: iter 1600, dev. ppl 39.723389\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 4, iter 1610, avg. loss 60.06, avg. ppl 11.52 cum. examples 320, speed 992.25 words/sec, time elapsed 434.98 sec\n",
            "epoch 4, iter 1620, avg. loss 56.98, avg. ppl 11.82 cum. examples 640, speed 3432.90 words/sec, time elapsed 437.13 sec\n",
            "epoch 4, iter 1630, avg. loss 65.35, avg. ppl 13.21 cum. examples 960, speed 3080.39 words/sec, time elapsed 439.76 sec\n",
            "epoch 4, iter 1640, avg. loss 58.59, avg. ppl 10.66 cum. examples 1280, speed 3306.04 words/sec, time elapsed 442.16 sec\n",
            "epoch 4, iter 1650, avg. loss 58.62, avg. ppl 11.08 cum. examples 1600, speed 3115.55 words/sec, time elapsed 444.67 sec\n",
            "epoch 4, iter 1660, avg. loss 63.15, avg. ppl 12.00 cum. examples 1920, speed 3260.52 words/sec, time elapsed 447.16 sec\n",
            "epoch 4, iter 1670, avg. loss 63.01, avg. ppl 12.42 cum. examples 2240, speed 2978.74 words/sec, time elapsed 449.85 sec\n",
            "epoch 4, iter 1680, avg. loss 57.82, avg. ppl 11.22 cum. examples 2560, speed 2938.88 words/sec, time elapsed 452.45 sec\n",
            "epoch 4, iter 1690, avg. loss 60.16, avg. ppl 10.62 cum. examples 2880, speed 3109.65 words/sec, time elapsed 455.07 sec\n",
            "epoch 4, iter 1700, avg. loss 57.24, avg. ppl 11.03 cum. examples 3200, speed 3447.78 words/sec, time elapsed 457.29 sec\n",
            "epoch 4, iter 1710, avg. loss 62.68, avg. ppl 11.84 cum. examples 3520, speed 3312.22 words/sec, time elapsed 459.74 sec\n",
            "epoch 4, iter 1720, avg. loss 59.42, avg. ppl 12.04 cum. examples 3840, speed 3144.88 words/sec, time elapsed 462.17 sec\n",
            "epoch 4, iter 1730, avg. loss 60.11, avg. ppl 12.21 cum. examples 4160, speed 3234.84 words/sec, time elapsed 464.54 sec\n",
            "epoch 4, iter 1740, avg. loss 56.36, avg. ppl 11.80 cum. examples 4480, speed 3240.72 words/sec, time elapsed 466.80 sec\n",
            "epoch 4, iter 1750, avg. loss 59.12, avg. ppl 11.21 cum. examples 4800, speed 3465.46 words/sec, time elapsed 469.06 sec\n",
            "epoch 4, iter 1760, avg. loss 66.16, avg. ppl 13.43 cum. examples 5120, speed 3076.09 words/sec, time elapsed 471.71 sec\n",
            "epoch 4, iter 1770, avg. loss 63.71, avg. ppl 13.05 cum. examples 5440, speed 3207.71 words/sec, time elapsed 474.18 sec\n",
            "epoch 4, iter 1780, avg. loss 59.07, avg. ppl 11.56 cum. examples 5760, speed 3515.71 words/sec, time elapsed 476.38 sec\n",
            "epoch 4, iter 1790, avg. loss 56.63, avg. ppl 11.61 cum. examples 6080, speed 3438.74 words/sec, time elapsed 478.53 sec\n",
            "epoch 4, iter 1800, avg. loss 61.94, avg. ppl 12.06 cum. examples 6400, speed 2851.45 words/sec, time elapsed 481.32 sec\n",
            "epoch 4, iter 1800, cum. loss 60.31, cum. ppl 11.80 cum. examples 6400\n",
            "begin validation ...\n",
            "validation: iter 1800, dev. ppl 39.887007\n",
            "hit patience 1\n",
            "hit #1 trial\n",
            "load previously best model and decay learning rate to 0.000250\n",
            "restore parameters of the optimizers\n",
            "epoch 4, iter 1810, avg. loss 58.07, avg. ppl 11.06 cum. examples 320, speed 1391.67 words/sec, time elapsed 486.88 sec\n",
            "epoch 4, iter 1820, avg. loss 63.90, avg. ppl 11.97 cum. examples 640, speed 3636.21 words/sec, time elapsed 489.14 sec\n",
            "epoch 4, iter 1830, avg. loss 57.44, avg. ppl 11.40 cum. examples 960, speed 3343.88 words/sec, time elapsed 491.40 sec\n",
            "epoch 4, iter 1840, avg. loss 53.46, avg. ppl 10.29 cum. examples 1280, speed 3574.04 words/sec, time elapsed 493.45 sec\n",
            "epoch 4, iter 1850, avg. loss 58.50, avg. ppl 10.25 cum. examples 1600, speed 3473.70 words/sec, time elapsed 495.77 sec\n",
            "epoch 4, iter 1860, avg. loss 54.78, avg. ppl 10.18 cum. examples 1920, speed 3471.65 words/sec, time elapsed 497.95 sec\n",
            "epoch 4, iter 1870, avg. loss 55.58, avg. ppl 10.12 cum. examples 2240, speed 3053.82 words/sec, time elapsed 500.46 sec\n",
            "epoch 4, iter 1880, avg. loss 58.35, avg. ppl 10.92 cum. examples 2560, speed 3493.43 words/sec, time elapsed 502.70 sec\n",
            "epoch 4, iter 1890, avg. loss 56.98, avg. ppl 10.34 cum. examples 2880, speed 3517.83 words/sec, time elapsed 504.92 sec\n",
            "epoch 4, iter 1900, avg. loss 55.71, avg. ppl 10.47 cum. examples 3200, speed 3334.05 words/sec, time elapsed 507.19 sec\n",
            "epoch 4, iter 1910, avg. loss 56.46, avg. ppl 9.97 cum. examples 3520, speed 3514.37 words/sec, time elapsed 509.43 sec\n",
            "epoch 4, iter 1920, avg. loss 57.21, avg. ppl 9.76 cum. examples 3840, speed 3309.29 words/sec, time elapsed 511.86 sec\n",
            "epoch 4, iter 1930, avg. loss 57.13, avg. ppl 10.92 cum. examples 4160, speed 3339.51 words/sec, time elapsed 514.15 sec\n",
            "epoch 4, iter 1940, avg. loss 54.97, avg. ppl 10.20 cum. examples 4480, speed 3474.07 words/sec, time elapsed 516.33 sec\n",
            "epoch 4, iter 1950, avg. loss 57.87, avg. ppl 10.98 cum. examples 4800, speed 2843.51 words/sec, time elapsed 519.05 sec\n",
            "epoch 4, iter 1960, avg. loss 54.28, avg. ppl 10.34 cum. examples 5120, speed 3345.60 words/sec, time elapsed 521.27 sec\n",
            "epoch 4, iter 1970, avg. loss 54.31, avg. ppl 9.48 cum. examples 5440, speed 3575.83 words/sec, time elapsed 523.43 sec\n",
            "epoch 4, iter 1980, avg. loss 60.14, avg. ppl 11.24 cum. examples 5760, speed 3600.35 words/sec, time elapsed 525.64 sec\n",
            "epoch 4, iter 1990, avg. loss 58.70, avg. ppl 11.11 cum. examples 6080, speed 3519.89 words/sec, time elapsed 527.86 sec\n",
            "epoch 4, iter 2000, avg. loss 52.40, avg. ppl 10.22 cum. examples 6400, speed 3608.03 words/sec, time elapsed 529.86 sec\n",
            "epoch 4, iter 2000, cum. loss 56.81, cum. ppl 10.55 cum. examples 6400\n",
            "begin validation ...\n",
            "validation: iter 2000, dev. ppl 37.942298\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 4, iter 2010, avg. loss 56.88, avg. ppl 10.51 cum. examples 320, speed 725.98 words/sec, time elapsed 540.52 sec\n",
            "epoch 4, iter 2020, avg. loss 58.95, avg. ppl 9.84 cum. examples 640, speed 3564.39 words/sec, time elapsed 542.83 sec\n",
            "epoch 4, iter 2030, avg. loss 59.73, avg. ppl 10.55 cum. examples 960, speed 3260.65 words/sec, time elapsed 545.32 sec\n",
            "epoch 4, iter 2040, avg. loss 55.66, avg. ppl 9.41 cum. examples 1280, speed 3129.58 words/sec, time elapsed 547.86 sec\n",
            "epoch 4, iter 2050, avg. loss 60.40, avg. ppl 10.48 cum. examples 1600, speed 2987.35 words/sec, time elapsed 550.61 sec\n",
            "epoch 4, iter 2060, avg. loss 60.39, avg. ppl 11.10 cum. examples 1920, speed 3247.10 words/sec, time elapsed 553.08 sec\n",
            "epoch 4, iter 2070, avg. loss 56.78, avg. ppl 10.17 cum. examples 2240, speed 3424.52 words/sec, time elapsed 555.37 sec\n",
            "epoch 4, iter 2080, avg. loss 59.31, avg. ppl 11.16 cum. examples 2560, speed 2947.11 words/sec, time elapsed 558.04 sec\n",
            "epoch 5, iter 2090, avg. loss 52.71, avg. ppl 8.97 cum. examples 2872, speed 3306.69 words/sec, time elapsed 560.31 sec\n",
            "epoch 5, iter 2100, avg. loss 48.02, avg. ppl 7.09 cum. examples 3192, speed 3562.01 words/sec, time elapsed 562.51 sec\n",
            "epoch 5, iter 2110, avg. loss 50.64, avg. ppl 8.28 cum. examples 3512, speed 2957.28 words/sec, time elapsed 565.10 sec\n",
            "epoch 5, iter 2120, avg. loss 49.60, avg. ppl 7.68 cum. examples 3832, speed 3280.76 words/sec, time elapsed 567.48 sec\n",
            "epoch 5, iter 2130, avg. loss 50.57, avg. ppl 7.77 cum. examples 4152, speed 3421.12 words/sec, time elapsed 569.78 sec\n",
            "epoch 5, iter 2140, avg. loss 48.37, avg. ppl 7.11 cum. examples 4472, speed 3541.04 words/sec, time elapsed 572.01 sec\n",
            "epoch 5, iter 2150, avg. loss 49.71, avg. ppl 7.89 cum. examples 4792, speed 3122.72 words/sec, time elapsed 574.48 sec\n",
            "epoch 5, iter 2160, avg. loss 51.23, avg. ppl 8.39 cum. examples 5112, speed 3526.21 words/sec, time elapsed 576.66 sec\n",
            "epoch 5, iter 2170, avg. loss 50.78, avg. ppl 8.02 cum. examples 5432, speed 3130.09 words/sec, time elapsed 579.16 sec\n",
            "epoch 5, iter 2180, avg. loss 50.41, avg. ppl 8.15 cum. examples 5752, speed 3305.56 words/sec, time elapsed 581.49 sec\n",
            "epoch 5, iter 2190, avg. loss 51.54, avg. ppl 8.40 cum. examples 6072, speed 3143.31 words/sec, time elapsed 583.95 sec\n",
            "epoch 5, iter 2200, avg. loss 55.52, avg. ppl 8.79 cum. examples 6392, speed 3167.52 words/sec, time elapsed 586.53 sec\n",
            "epoch 5, iter 2200, cum. loss 53.86, cum. ppl 8.91 cum. examples 6392\n",
            "begin validation ...\n",
            "validation: iter 2200, dev. ppl 38.702363\n",
            "hit patience 1\n",
            "hit #2 trial\n",
            "load previously best model and decay learning rate to 0.000125\n",
            "restore parameters of the optimizers\n",
            "epoch 5, iter 2210, avg. loss 53.04, avg. ppl 8.83 cum. examples 320, speed 1356.72 words/sec, time elapsed 592.28 sec\n",
            "epoch 5, iter 2220, avg. loss 53.22, avg. ppl 8.73 cum. examples 640, speed 3166.31 words/sec, time elapsed 594.76 sec\n",
            "epoch 5, iter 2230, avg. loss 52.42, avg. ppl 8.80 cum. examples 960, speed 3303.01 words/sec, time elapsed 597.10 sec\n",
            "epoch 5, iter 2240, avg. loss 49.94, avg. ppl 8.16 cum. examples 1280, speed 3225.41 words/sec, time elapsed 599.46 sec\n",
            "epoch 5, iter 2250, avg. loss 54.11, avg. ppl 9.10 cum. examples 1600, speed 2882.09 words/sec, time elapsed 602.18 sec\n",
            "epoch 5, iter 2260, avg. loss 49.80, avg. ppl 8.45 cum. examples 1920, speed 3516.25 words/sec, time elapsed 604.30 sec\n",
            "epoch 5, iter 2270, avg. loss 49.67, avg. ppl 8.27 cum. examples 2240, speed 3310.52 words/sec, time elapsed 606.57 sec\n",
            "epoch 5, iter 2280, avg. loss 51.63, avg. ppl 8.02 cum. examples 2560, speed 3280.88 words/sec, time elapsed 608.99 sec\n",
            "epoch 5, iter 2290, avg. loss 53.07, avg. ppl 7.84 cum. examples 2880, speed 3380.41 words/sec, time elapsed 611.43 sec\n",
            "epoch 5, iter 2300, avg. loss 50.81, avg. ppl 8.21 cum. examples 3200, speed 3555.93 words/sec, time elapsed 613.60 sec\n",
            "epoch 5, iter 2310, avg. loss 52.03, avg. ppl 8.43 cum. examples 3520, speed 3364.34 words/sec, time elapsed 615.93 sec\n",
            "epoch 5, iter 2320, avg. loss 51.83, avg. ppl 8.37 cum. examples 3840, speed 3349.45 words/sec, time elapsed 618.26 sec\n",
            "epoch 5, iter 2330, avg. loss 54.60, avg. ppl 9.20 cum. examples 4160, speed 2935.15 words/sec, time elapsed 620.94 sec\n",
            "epoch 5, iter 2340, avg. loss 50.57, avg. ppl 8.26 cum. examples 4480, speed 3279.62 words/sec, time elapsed 623.28 sec\n",
            "epoch 5, iter 2350, avg. loss 48.40, avg. ppl 7.77 cum. examples 4800, speed 3351.19 words/sec, time elapsed 625.53 sec\n",
            "epoch 5, iter 2360, avg. loss 52.92, avg. ppl 8.44 cum. examples 5120, speed 3411.34 words/sec, time elapsed 627.86 sec\n",
            "epoch 5, iter 2370, avg. loss 50.73, avg. ppl 8.16 cum. examples 5440, speed 2988.87 words/sec, time elapsed 630.45 sec\n",
            "epoch 5, iter 2380, avg. loss 51.91, avg. ppl 8.20 cum. examples 5760, speed 3047.33 words/sec, time elapsed 633.04 sec\n",
            "epoch 5, iter 2390, avg. loss 51.20, avg. ppl 8.36 cum. examples 6080, speed 3369.42 words/sec, time elapsed 635.33 sec\n",
            "epoch 5, iter 2400, avg. loss 54.04, avg. ppl 8.14 cum. examples 6400, speed 3562.28 words/sec, time elapsed 637.64 sec\n",
            "epoch 5, iter 2400, cum. loss 51.80, cum. ppl 8.38 cum. examples 6400\n",
            "begin validation ...\n",
            "validation: iter 2400, dev. ppl 38.284317\n",
            "hit patience 1\n",
            "hit #3 trial\n",
            "load previously best model and decay learning rate to 0.000063\n",
            "restore parameters of the optimizers\n",
            "epoch 5, iter 2410, avg. loss 49.19, avg. ppl 7.98 cum. examples 320, speed 1385.97 words/sec, time elapsed 643.11 sec\n",
            "epoch 5, iter 2420, avg. loss 49.87, avg. ppl 8.06 cum. examples 640, speed 3556.32 words/sec, time elapsed 645.26 sec\n",
            "epoch 5, iter 2430, avg. loss 55.54, avg. ppl 8.71 cum. examples 960, speed 3405.89 words/sec, time elapsed 647.67 sec\n",
            "epoch 5, iter 2440, avg. loss 50.20, avg. ppl 7.90 cum. examples 1280, speed 3584.73 words/sec, time elapsed 649.84 sec\n",
            "epoch 5, iter 2450, avg. loss 54.14, avg. ppl 8.57 cum. examples 1600, speed 3570.32 words/sec, time elapsed 652.10 sec\n",
            "epoch 5, iter 2460, avg. loss 53.20, avg. ppl 8.26 cum. examples 1920, speed 3380.57 words/sec, time elapsed 654.48 sec\n",
            "epoch 5, iter 2470, avg. loss 53.83, avg. ppl 8.84 cum. examples 2240, speed 3128.91 words/sec, time elapsed 657.01 sec\n",
            "epoch 5, iter 2480, avg. loss 49.43, avg. ppl 8.13 cum. examples 2560, speed 3418.25 words/sec, time elapsed 659.22 sec\n",
            "epoch 5, iter 2490, avg. loss 54.36, avg. ppl 9.13 cum. examples 2880, speed 2967.77 words/sec, time elapsed 661.87 sec\n",
            "epoch 5, iter 2500, avg. loss 49.07, avg. ppl 7.88 cum. examples 3200, speed 3555.72 words/sec, time elapsed 664.01 sec\n",
            "epoch 5, iter 2510, avg. loss 48.83, avg. ppl 7.85 cum. examples 3520, speed 3203.02 words/sec, time elapsed 666.37 sec\n",
            "epoch 5, iter 2520, avg. loss 53.19, avg. ppl 8.63 cum. examples 3840, speed 3148.04 words/sec, time elapsed 668.88 sec\n",
            "epoch 5, iter 2530, avg. loss 53.44, avg. ppl 8.56 cum. examples 4160, speed 3418.21 words/sec, time elapsed 671.22 sec\n",
            "epoch 5, iter 2540, avg. loss 47.13, avg. ppl 7.62 cum. examples 4480, speed 3081.91 words/sec, time elapsed 673.63 sec\n",
            "epoch 5, iter 2550, avg. loss 49.71, avg. ppl 7.93 cum. examples 4800, speed 3249.33 words/sec, time elapsed 675.99 sec\n",
            "epoch 5, iter 2560, avg. loss 54.89, avg. ppl 8.42 cum. examples 5120, speed 3189.08 words/sec, time elapsed 678.57 sec\n",
            "epoch 5, iter 2570, avg. loss 52.13, avg. ppl 8.37 cum. examples 5440, speed 3580.06 words/sec, time elapsed 680.77 sec\n",
            "epoch 5, iter 2580, avg. loss 53.57, avg. ppl 8.17 cum. examples 5760, speed 3107.90 words/sec, time elapsed 683.39 sec\n",
            "epoch 5, iter 2590, avg. loss 47.88, avg. ppl 6.95 cum. examples 6080, speed 3514.57 words/sec, time elapsed 685.64 sec\n",
            "epoch 5, iter 2600, avg. loss 50.72, avg. ppl 8.28 cum. examples 6400, speed 3428.74 words/sec, time elapsed 687.88 sec\n",
            "epoch 5, iter 2600, cum. loss 51.52, cum. ppl 8.21 cum. examples 6400\n",
            "begin validation ...\n",
            "validation: iter 2600, dev. ppl 37.724823\n",
            "save currently the best model to [model.bin]\n",
            "save model parameters to [model.bin]\n",
            "epoch 5, iter 2610, avg. loss 51.24, avg. ppl 8.00 cum. examples 312, speed 918.31 words/sec, time elapsed 696.25 sec\n",
            "epoch 6, iter 2620, avg. loss 51.47, avg. ppl 7.68 cum. examples 632, speed 3728.79 words/sec, time elapsed 698.42 sec\n",
            "epoch 6, iter 2630, avg. loss 48.12, avg. ppl 7.41 cum. examples 952, speed 2988.26 words/sec, time elapsed 700.99 sec\n",
            "epoch 6, iter 2640, avg. loss 53.58, avg. ppl 8.79 cum. examples 1272, speed 2899.52 words/sec, time elapsed 703.71 sec\n",
            "epoch 6, iter 2650, avg. loss 48.37, avg. ppl 6.92 cum. examples 1592, speed 3413.50 words/sec, time elapsed 706.06 sec\n",
            "epoch 6, iter 2660, avg. loss 54.31, avg. ppl 8.21 cum. examples 1912, speed 2765.71 words/sec, time elapsed 709.04 sec\n",
            "epoch 6, iter 2670, avg. loss 48.29, avg. ppl 7.77 cum. examples 2232, speed 3399.33 words/sec, time elapsed 711.26 sec\n",
            "epoch 6, iter 2680, avg. loss 47.59, avg. ppl 7.04 cum. examples 2552, speed 3307.46 words/sec, time elapsed 713.62 sec\n",
            "epoch 6, iter 2690, avg. loss 51.26, avg. ppl 7.69 cum. examples 2872, speed 2895.92 words/sec, time elapsed 716.40 sec\n",
            "epoch 6, iter 2700, avg. loss 49.42, avg. ppl 7.49 cum. examples 3192, speed 3484.94 words/sec, time elapsed 718.65 sec\n",
            "epoch 6, iter 2710, avg. loss 46.32, avg. ppl 6.68 cum. examples 3512, speed 3393.38 words/sec, time elapsed 720.95 sec\n",
            "epoch 6, iter 2720, avg. loss 48.35, avg. ppl 7.19 cum. examples 3832, speed 3296.08 words/sec, time elapsed 723.33 sec\n",
            "epoch 6, iter 2730, avg. loss 53.12, avg. ppl 8.23 cum. examples 4152, speed 2919.74 words/sec, time elapsed 726.09 sec\n",
            "epoch 6, iter 2740, avg. loss 49.12, avg. ppl 7.48 cum. examples 4472, speed 3357.29 words/sec, time elapsed 728.42 sec\n",
            "epoch 6, iter 2750, avg. loss 55.10, avg. ppl 7.94 cum. examples 4792, speed 3244.75 words/sec, time elapsed 731.04 sec\n",
            "epoch 6, iter 2760, avg. loss 48.76, avg. ppl 7.66 cum. examples 5112, speed 3644.29 words/sec, time elapsed 733.15 sec\n",
            "epoch 6, iter 2770, avg. loss 54.23, avg. ppl 8.17 cum. examples 5432, speed 3378.90 words/sec, time elapsed 735.59 sec\n",
            "epoch 6, iter 2780, avg. loss 48.54, avg. ppl 6.90 cum. examples 5752, speed 3464.73 words/sec, time elapsed 737.91 sec\n",
            "epoch 6, iter 2790, avg. loss 47.42, avg. ppl 7.63 cum. examples 6072, speed 3045.28 words/sec, time elapsed 740.36 sec\n",
            "epoch 6, iter 2800, avg. loss 50.43, avg. ppl 8.05 cum. examples 6392, speed 3367.12 words/sec, time elapsed 742.66 sec\n",
            "epoch 6, iter 2800, cum. loss 50.25, cum. ppl 7.63 cum. examples 6392\n",
            "begin validation ...\n",
            "validation: iter 2800, dev. ppl 38.324129\n",
            "hit patience 1\n",
            "hit #4 trial\n",
            "load previously best model and decay learning rate to 0.000031\n",
            "restore parameters of the optimizers\n",
            "epoch 6, iter 2810, avg. loss 48.95, avg. ppl 7.77 cum. examples 320, speed 1380.20 words/sec, time elapsed 748.20 sec\n",
            "epoch 6, iter 2820, avg. loss 48.09, avg. ppl 7.67 cum. examples 640, speed 3101.56 words/sec, time elapsed 750.63 sec\n",
            "epoch 6, iter 2830, avg. loss 51.02, avg. ppl 7.85 cum. examples 960, speed 3587.61 words/sec, time elapsed 752.84 sec\n",
            "epoch 6, iter 2840, avg. loss 45.12, avg. ppl 7.36 cum. examples 1280, speed 2846.67 words/sec, time elapsed 755.38 sec\n",
            "epoch 6, iter 2850, avg. loss 50.29, avg. ppl 7.73 cum. examples 1600, speed 3413.15 words/sec, time elapsed 757.69 sec\n",
            "epoch 6, iter 2860, avg. loss 45.40, avg. ppl 6.82 cum. examples 1920, speed 3607.23 words/sec, time elapsed 759.79 sec\n",
            "epoch 6, iter 2870, avg. loss 50.63, avg. ppl 7.63 cum. examples 2240, speed 3364.74 words/sec, time elapsed 762.16 sec\n",
            "epoch 6, iter 2880, avg. loss 45.73, avg. ppl 7.09 cum. examples 2560, speed 3310.29 words/sec, time elapsed 764.41 sec\n",
            "epoch 6, iter 2890, avg. loss 48.63, avg. ppl 7.48 cum. examples 2880, speed 3037.87 words/sec, time elapsed 766.96 sec\n",
            "epoch 6, iter 2900, avg. loss 49.05, avg. ppl 7.60 cum. examples 3200, speed 3332.56 words/sec, time elapsed 769.28 sec\n",
            "epoch 6, iter 2910, avg. loss 45.97, avg. ppl 6.84 cum. examples 3520, speed 3559.43 words/sec, time elapsed 771.43 sec\n",
            "epoch 6, iter 2920, avg. loss 52.21, avg. ppl 7.58 cum. examples 3840, speed 3125.02 words/sec, time elapsed 774.07 sec\n",
            "epoch 6, iter 2930, avg. loss 52.77, avg. ppl 7.99 cum. examples 4160, speed 3315.52 words/sec, time elapsed 776.52 sec\n",
            "epoch 6, iter 2940, avg. loss 48.81, avg. ppl 7.51 cum. examples 4480, speed 3081.26 words/sec, time elapsed 779.04 sec\n",
            "epoch 6, iter 2950, avg. loss 47.21, avg. ppl 6.93 cum. examples 4800, speed 3373.96 words/sec, time elapsed 781.35 sec\n",
            "epoch 6, iter 2960, avg. loss 46.69, avg. ppl 7.12 cum. examples 5120, speed 3650.88 words/sec, time elapsed 783.44 sec\n",
            "epoch 6, iter 2970, avg. loss 50.86, avg. ppl 8.41 cum. examples 5440, speed 3218.23 words/sec, time elapsed 785.81 sec\n",
            "epoch 6, iter 2980, avg. loss 48.94, avg. ppl 7.61 cum. examples 5760, speed 3417.06 words/sec, time elapsed 788.07 sec\n",
            "epoch 6, iter 2990, avg. loss 49.97, avg. ppl 7.45 cum. examples 6080, speed 3430.70 words/sec, time elapsed 790.39 sec\n",
            "epoch 6, iter 3000, avg. loss 53.03, avg. ppl 8.20 cum. examples 6400, speed 3039.75 words/sec, time elapsed 793.04 sec\n",
            "epoch 6, iter 3000, cum. loss 48.97, cum. ppl 7.52 cum. examples 6400\n",
            "begin validation ...\n",
            "validation: iter 3000, dev. ppl 38.196579\n",
            "hit patience 1\n",
            "hit #5 trial\n",
            "early stop!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python3 run.py decode model.bin ./chr_en_data/test.chr ./chr_en_data/test.en outputs/test_outputs.txt --cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz5SZ4oeHh0e",
        "outputId": "5de04896-960f-4218-cf41-43c2fc37e468"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "2024-06-19 06:25:21.486132: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-19 06:25:21.486201: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-19 06:25:21.488333: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-19 06:25:21.499583: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-19 06:25:23.095493: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "load test source sentences from [./chr_en_data/test.chr]\n",
            "load test target sentences from [./chr_en_data/test.en]\n",
            "load model from model.bin\n",
            "Decoding: 100% 1000/1000 [00:42<00:00, 23.75it/s]\n",
            "Corpus BLEU: 12.407267255720656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VzHSZQyKK8gt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}